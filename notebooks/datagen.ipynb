{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen example\n",
    "\n",
    "From: https://databrickslabs.github.io/dbldatagen/public_docs/multi_table_data.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4a5e349-51c3-455f-809b-2ef88e019d0e",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "pip install dbldatagen jmespath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e7eedcf-7499-434d-840c-39b8b6870a4b",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "MARGIN_PATTERN= re.compile(r\"\\s*\\|\")  # margin detection pattern for stripMargin\n",
    "def stripMargin(s): \n",
    "  \"\"\"  strip margin removes leading space in multi line string before '|' \"\"\"\n",
    "  return \"\\n\".join(re.split(MARGIN_PATTERN, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee93f8ca-fd40-4786-a1ad-587f5c525826",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dbldatagen as dg\n",
    "\n",
    "# clear cache so that if we run multiple times to check performance, we're not relying on cache\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "UNIQUE_PLANS = 20\n",
    "PLAN_MIN_VALUE = 100\n",
    "\n",
    "shuffle_partitions_requested = 8\n",
    "partitions_requested = 1\n",
    "data_rows = UNIQUE_PLANS # we'll generate one row for each plan\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", shuffle_partitions_requested)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", 20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c440b905-231a-4165-8843-ca2eaca16e03",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[plan_id: int, plan_name: string, cost_per_mb: decimal(5,3), cost_per_message: decimal(5,3), cost_per_minute: decimal(5,3), ld_cost_per_minute: decimal(5,3), intl_cost_per_minute: decimal(5,3)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plan_dataspec = (dg.DataGenerator(spark, rows=data_rows, partitions=partitions_requested)\n",
    "            .withColumn(\"plan_id\",\"int\", minValue=PLAN_MIN_VALUE, uniqueValues=UNIQUE_PLANS)\n",
    "            .withColumn(\"plan_name\", prefix=\"plan\", baseColumn=\"plan_id\")  # use plan_id as root value\n",
    "                \n",
    "            # note default step is 1 so you must specify a step for small number ranges, \n",
    "            .withColumn(\"cost_per_mb\", \"decimal(5,3)\", minValue=0.005, maxValue=0.050, step=0.005, random=True)  \n",
    "            .withColumn(\"cost_per_message\", \"decimal(5,3)\", minValue=0.001, maxValue=0.02, step=0.001, random=True)  \n",
    "            .withColumn(\"cost_per_minute\", \"decimal(5,3)\", minValue=0.001, maxValue=0.01, step=0.001, random=True)  \n",
    "                \n",
    "            # we're modelling long distance and international prices simplistically - each is a multiplier thats applied to base rate\n",
    "            .withColumn(\"ld_multiplier\", \"decimal(5,3)\", minValue=1.5, maxValue=3, step=0.05, random=True, \n",
    "                        distribution=\"normal\", omit=True)  \n",
    "            .withColumn(\"ld_cost_per_minute\", \"decimal(5,3)\", expr=\"cost_per_minute * ld_multiplier\", \n",
    "                        baseColumns=['cost_per_minute', 'ld_multiplier'])  \n",
    "            .withColumn(\"intl_multiplier\", \"decimal(5,3)\", minValue=2, maxValue=4, step=0.05, random=True, \n",
    "                        distribution=\"normal\", omit=True)  \n",
    "            .withColumn(\"intl_cost_per_minute\", \"decimal(5,3)\", expr=\"cost_per_minute * intl_multiplier\", \n",
    "                        baseColumns=['cost_per_minute', 'intl_multiplier'])  \n",
    "                \n",
    "            )\n",
    "df_plans = (plan_dataspec.build()\n",
    "            .cache()\n",
    "           )\n",
    "\n",
    "display(df_plans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+----------------+---------------+------------------+--------------------+\n",
      "|plan_id|plan_name|cost_per_mb|cost_per_message|cost_per_minute|ld_cost_per_minute|intl_cost_per_minute|\n",
      "+-------+---------+-----------+----------------+---------------+------------------+--------------------+\n",
      "|    100| plan_100|      0.025|           0.012|          0.010|             0.030|               0.031|\n",
      "|    101| plan_101|      0.045|           0.018|          0.005|             0.013|               0.015|\n",
      "|    102| plan_102|      0.005|           0.007|          0.008|             0.014|               0.032|\n",
      "|    103| plan_103|      0.015|           0.006|          0.006|             0.009|               0.012|\n",
      "|    104| plan_104|      0.010|           0.011|          0.001|             0.003|               0.002|\n",
      "|    105| plan_105|      0.030|           0.014|          0.007|             0.014|               0.020|\n",
      "|    106| plan_106|      0.020|           0.020|          0.006|             0.014|               0.017|\n",
      "|    107| plan_107|      0.025|           0.017|          0.006|             0.010|               0.020|\n",
      "|    108| plan_108|      0.010|           0.001|          0.001|             0.003|               0.003|\n",
      "|    109| plan_109|      0.030|           0.005|          0.009|             0.019|               0.021|\n",
      "|    110| plan_110|      0.050|           0.020|          0.010|             0.018|               0.027|\n",
      "|    111| plan_111|      0.005|           0.015|          0.008|             0.015|               0.022|\n",
      "|    112| plan_112|      0.040|           0.018|          0.009|             0.020|               0.022|\n",
      "|    113| plan_113|      0.015|           0.011|          0.006|             0.011|               0.020|\n",
      "|    114| plan_114|      0.040|           0.016|          0.003|             0.008|               0.009|\n",
      "|    115| plan_115|      0.030|           0.010|          0.007|             0.013|               0.021|\n",
      "|    116| plan_116|      0.015|           0.011|          0.007|             0.019|               0.018|\n",
      "|    117| plan_117|      0.015|           0.008|          0.009|             0.019|               0.024|\n",
      "|    118| plan_118|      0.010|           0.015|          0.010|             0.022|               0.038|\n",
      "|    119| plan_119|      0.020|           0.011|          0.005|             0.012|               0.016|\n",
      "+-------+---------+-----------+----------------+---------------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_plans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cac35211-160e-4c20-a4a7-34f2bd61e2b6",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revised customers : 50000,\n",
      "   unique customers: 50000,\n",
      "   unique device ids: 50000,\n",
      "   unique phone numbers: 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[customer_id: decimal(10,0), customer_name: string, device_id: decimal(10,0), phone_number: decimal(10,0), email: string, plan: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dbldatagen as dg\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", shuffle_partitions_requested)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", 20000)\n",
    "\n",
    "UNIQUE_CUSTOMERS = 50000\n",
    "CUSTOMER_MIN_VALUE = 1000\n",
    "DEVICE_MIN_VALUE = 1000000000\n",
    "SUBSCRIBER_NUM_MIN_VALUE = 1000000000\n",
    "\n",
    "spark.catalog.clearCache()  # clear cache so that if we run multiple times to check performance, we're not relying on cache\n",
    "shuffle_partitions_requested = 8\n",
    "partitions_requested = 8\n",
    "data_rows = UNIQUE_CUSTOMERS\n",
    "\n",
    "customer_dataspec = (dg.DataGenerator(spark, rows=data_rows, partitions=partitions_requested)\n",
    "            .withColumn(\"customer_id\",\"decimal(10)\", minValue=CUSTOMER_MIN_VALUE, uniqueValues=UNIQUE_CUSTOMERS)\n",
    "            .withColumn(\"customer_name\", template=r\"\\\\w \\\\w|\\\\w a. \\\\w\")  \n",
    "           \n",
    "            # use the following for a simple sequence\n",
    "            #.withColumn(\"device_id\",\"decimal(10)\", minValue=DEVICE_MIN_VALUE, uniqueValues=UNIQUE_CUSTOMERS)\n",
    "                     \n",
    "            .withColumn(\"device_id\",\"decimal(10)\",  minValue=DEVICE_MIN_VALUE, \n",
    "                        baseColumn=\"customer_id\", baseColumnType=\"hash\")\n",
    "\n",
    "            .withColumn(\"phone_number\",\"decimal(10)\",  minValue=SUBSCRIBER_NUM_MIN_VALUE, \n",
    "                        baseColumn=[\"customer_id\", \"customer_name\"], baseColumnType=\"hash\")\n",
    "\n",
    "            # for email, we'll just use the formatted phone number\n",
    "            .withColumn(\"email\",\"string\",  format=\"subscriber_%s@myoperator.com\", baseColumn=\"phone_number\")\n",
    "            .withColumn(\"plan\", \"int\", minValue=PLAN_MIN_VALUE, uniqueValues=UNIQUE_PLANS, random=True)\n",
    "            )\n",
    "\n",
    "df_customers = (customer_dataspec.build()\n",
    "                .dropDuplicates([\"device_id\"])\n",
    "                .dropDuplicates([\"phone_number\"])\n",
    "                .orderBy(\"customer_id\")\n",
    "                .cache()\n",
    "               )\n",
    "\n",
    "effective_customers = df_customers.count()\n",
    "\n",
    "print(stripMargin(f\"\"\"revised customers : {df_customers.count()}, \n",
    "       |   unique customers: {df_customers.select(F.countDistinct('customer_id')).take(1)[0][0]}, \n",
    "       |   unique device ids: {df_customers.select(F.countDistinct('device_id')).take(1)[0][0]},\n",
    "       |   unique phone numbers: {df_customers.select(F.countDistinct('phone_number')).take(1)[0][0]}\"\"\")\n",
    "     )\n",
    "\n",
    "display(df_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+------------+--------------------+----+\n",
      "|customer_id|       customer_name| device_id|phone_number|               email|plan|\n",
      "+-----------+--------------------+----------+------------+--------------------+----+\n",
      "|       1000|  commodo m. nostrud|9196676281|  1046828624|subscriber_104682...| 118|\n",
      "|       1001|               do ex|7945719524|  3100324535|subscriber_310032...| 108|\n",
      "|       1002|        anim o. anim|1018593222|  8004658441|subscriber_800465...| 106|\n",
      "|       1003|        dolor k. est|9858441589|  8174126224|subscriber_817412...| 115|\n",
      "|       1004|   proident deserunt|1907930576|  2004998683|subscriber_200499...| 110|\n",
      "|       1005|    pariatur r. aute|8365271101|  8633827457|subscriber_863382...| 117|\n",
      "|       1006|adipiscing o. cup...|2906230381|  7923251099|subscriber_792325...| 118|\n",
      "|       1007|          sunt t. ea|2027317295|  8445814606|subscriber_844581...| 103|\n",
      "|       1008|    adipiscing dolor|9328194574|  2714866555|subscriber_271486...| 114|\n",
      "|       1009|         ullamco non|9702890862|  9328033138|subscriber_932803...| 114|\n",
      "|       1010|           veniam ex|3032342201|  1947099641|subscriber_194709...| 111|\n",
      "|       1011|   irure h. deserunt|1782282895|  8794619103|subscriber_879461...| 115|\n",
      "|       1012|          ipsum nisi|3133878245|  2036904645|subscriber_203690...| 102|\n",
      "|       1013|      velit o. velit|2860935491|  1918034572|subscriber_191803...| 102|\n",
      "|       1014|           enim quis|2411226554|  7993821876|subscriber_799382...| 117|\n",
      "|       1015|          do w. enim|2512328750|  8081378094|subscriber_808137...| 113|\n",
      "|       1016|     incididunt sunt|9503074040|  8520737370|subscriber_852073...| 114|\n",
      "|       1017|        eu voluptate|8671424789|  9962261035|subscriber_996226...| 101|\n",
      "|       1018|      elit f. labore|9538376524|  9520684964|subscriber_952068...| 100|\n",
      "|       1019|      culpa c. culpa|9658843172|  8788714751|subscriber_878871...| 113|\n",
      "+-----------+--------------------+----------+------------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97ccd5af-cd5b-4a44-8796-17bfacbb5eea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[device_id: decimal(10,0), event_type: string, minutes: decimal(7,2), bytes_transferred: decimal(12,0), event_ts: timestamp]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dbldatagen as dg\n",
    "\n",
    "AVG_EVENTS_PER_CUSTOMER = 50\n",
    "\n",
    "spark.catalog.clearCache()  # clear cache so that if we run multiple times to check performance, we're not relying on cache\n",
    "shuffle_partitions_requested = 8\n",
    "partitions_requested = 8\n",
    "NUM_DAYS=31\n",
    "MB_100 = 100 * 1000 * 1000\n",
    "K_1 = 1000\n",
    "data_rows = AVG_EVENTS_PER_CUSTOMER * UNIQUE_CUSTOMERS * NUM_DAYS\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", shuffle_partitions_requested)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", 20000)\n",
    "\n",
    "\n",
    "# use random seed method of 'hash_fieldname' for better spread - default in later builds\n",
    "events_dataspec = (dg.DataGenerator(spark, rows=data_rows, partitions=partitions_requested, randomSeed=42,\n",
    "                                    randomSeedMethod=\"hash_fieldname\")\n",
    "             # use same logic as per customers dataset to ensure matching keys - but make them random\n",
    "            .withColumn(\"device_id_base\", \"decimal(10)\", minValue=CUSTOMER_MIN_VALUE, uniqueValues=UNIQUE_CUSTOMERS,\n",
    "                        random=True, omit=True)\n",
    "            .withColumn(\"device_id\", \"decimal(10)\",  minValue=DEVICE_MIN_VALUE,\n",
    "                        baseColumn=\"device_id_base\", baseColumnType=\"hash\")\n",
    "\n",
    "            # use specific random seed to get better spread of values\n",
    "            .withColumn(\"event_type\", \"string\",  values=[\"sms\", \"internet\", \"local call\", \"ld call\", \"intl call\"],\n",
    "                                                weights=[50, 50, 20, 10, 5], random=True)\n",
    "\n",
    "            # use Gamma distribution for skew towards short calls\n",
    "            .withColumn(\"base_minutes\",\"decimal(7,2)\",  minValue=1.0, maxValue=100.0, step=0.1,\n",
    "                        distribution=dg.distributions.Gamma(shape=1.5, scale=2.0), random=True, omit=True)\n",
    "                   \n",
    "            # use Gamma distribution for skew towards short transfers\n",
    "            .withColumn(\"base_bytes_transferred\",\"decimal(12)\",  minValue=K_1, maxValue=MB_100, \n",
    "                        distribution=dg.distributions.Gamma(shape=0.75, scale=2.0), random=True, omit=True)\n",
    "                   \n",
    "            .withColumn(\"minutes\", \"decimal(7,2)\", baseColumn=[\"event_type\", \"base_minutes\"],\n",
    "                        expr=\"\"\"\n",
    "                              case when event_type in (\"local call\", \"ld call\", \"intl call\") then base_minutes\n",
    "                              else 0\n",
    "                              end\n",
    "                               \"\"\")\n",
    "            .withColumn(\"bytes_transferred\", \"decimal(12)\", baseColumn=[\"event_type\", \"base_bytes_transferred\"],\n",
    "                        expr=\"\"\"\n",
    "                              case when event_type = \"internet\" then base_bytes_transferred\n",
    "                              else 0\n",
    "                              end\n",
    "                               \"\"\")\n",
    "                   \n",
    "            .withColumn(\"event_ts\", \"timestamp\", data_range=dg.DateRange(\"2020-07-01 00:00:00\",\n",
    "                                                                             \"2020-07-31 11:59:59\",\n",
    "                                                                             \"seconds=1\"),\n",
    "                        random=True)\n",
    "                   \n",
    "            )\n",
    "\n",
    "df_events = (events_dataspec.build()\n",
    "               )\n",
    "\n",
    "display(df_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-----------------+-------------------+\n",
      "| device_id|event_type|minutes|bytes_transferred|           event_ts|\n",
      "+----------+----------+-------+-----------------+-------------------+\n",
      "|8783384069|local call|   5.90|                0|2020-07-26 16:17:55|\n",
      "|8766749269|       sms|   0.00|                0|2020-07-23 14:06:49|\n",
      "|8944400746|       sms|   0.00|                0|2020-07-18 04:56:45|\n",
      "|8471543556|       sms|   0.00|                0|2020-07-04 02:02:40|\n",
      "|1954922029|       sms|   0.00|                0|2020-07-16 12:06:18|\n",
      "|8158729839|  internet|   0.00|           520279|2020-07-02 23:47:56|\n",
      "|9534966611|   ld call|   1.10|                0|2020-07-20 12:20:28|\n",
      "|2395997193|local call|  13.90|                0|2020-07-28 08:30:32|\n",
      "|9043775345|       sms|   0.00|                0|2020-07-30 06:33:32|\n",
      "|9445756890|       sms|   0.00|                0|2020-07-27 17:38:34|\n",
      "|9852527388|  internet|   0.00|           897661|2020-07-16 05:37:01|\n",
      "|9853758216|       sms|   0.00|                0|2020-07-06 02:18:21|\n",
      "|9617500674| intl call|   4.20|                0|2020-07-24 13:16:51|\n",
      "|8751139723|       sms|   0.00|                0|2020-07-13 15:36:24|\n",
      "|9792386930|       sms|   0.00|                0|2020-07-07 18:32:22|\n",
      "|9910852203|       sms|   0.00|                0|2020-07-09 04:53:09|\n",
      "|9866799997|  internet|   0.00|          6040146|2020-07-14 13:38:42|\n",
      "|8980756154|       sms|   0.00|                0|2020-07-23 16:03:53|\n",
      "|9183043331|       sms|   0.00|                0|2020-07-19 10:55:37|\n",
      "|1747217698|local call|  11.90|                0|2020-07-30 06:29:08|\n",
      "+----------+----------+-------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_events.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cbbd3ba-4eb8-41c4-a491-e3f11b447130",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[customer_id: decimal(10,0), customer_name: string, device_id: decimal(10,0), phone_number: decimal(10,0), email: string, plan: int, plan_id: int, plan_name: string, cost_per_mb: decimal(5,3), cost_per_message: decimal(5,3), cost_per_minute: decimal(5,3), ld_cost_per_minute: decimal(5,3), intl_cost_per_minute: decimal(5,3)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_customer_pricing = df_customers.join(df_plans, df_plans.plan_id == df_customers.plan)\n",
    "\n",
    "display(df_customer_pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+------------+--------------------+----+-------+---------+-----------+----------------+---------------+------------------+--------------------+\n",
      "|customer_id|       customer_name| device_id|phone_number|               email|plan|plan_id|plan_name|cost_per_mb|cost_per_message|cost_per_minute|ld_cost_per_minute|intl_cost_per_minute|\n",
      "+-----------+--------------------+----------+------------+--------------------+----+-------+---------+-----------+----------------+---------------+------------------+--------------------+\n",
      "|      50523|          nisi c. id|9474651738|  1000111976|subscriber_100011...| 107|    107| plan_107|      0.025|           0.017|          0.006|             0.010|               0.020|\n",
      "|       3916|       dolor commodo|2599584759|  1000238254|subscriber_100023...| 107|    107| plan_107|      0.025|           0.017|          0.006|             0.010|               0.020|\n",
      "|      41040|             non est|1344902705|  1000703061|subscriber_100070...| 101|    101| plan_101|      0.045|           0.018|          0.005|             0.013|               0.015|\n",
      "|      39220|         ut d. dolor|2984164138|  1000713337|subscriber_100071...| 115|    115| plan_115|      0.030|           0.010|          0.007|             0.013|               0.021|\n",
      "|      37761|          ex eiusmod|2755053125|  1000871091|subscriber_100087...| 116|    116| plan_116|      0.015|           0.011|          0.007|             0.019|               0.018|\n",
      "|      30458|          ad aliquip|1295667426|  1001175657|subscriber_100117...| 118|    118| plan_118|      0.010|           0.015|          0.010|             0.022|               0.038|\n",
      "|       6319| pariatur l. officia|3053313204|  1001220745|subscriber_100122...| 114|    114| plan_114|      0.040|           0.016|          0.003|             0.008|               0.009|\n",
      "|       3512|      sed i. officia|1128644352|  1001271884|subscriber_100127...| 101|    101| plan_101|      0.045|           0.018|          0.005|             0.013|               0.015|\n",
      "|      21224| laboris p. proident|2779173094|  1001632400|subscriber_100163...| 101|    101| plan_101|      0.045|           0.018|          0.005|             0.013|               0.015|\n",
      "|      16316|      cillum aliquip|2465212015|  1002007635|subscriber_100200...| 117|    117| plan_117|      0.015|           0.008|          0.009|             0.019|               0.024|\n",
      "|      36936|      occaecat k. in|2004837205|  1002077086|subscriber_100207...| 112|    112| plan_112|      0.040|           0.018|          0.009|             0.020|               0.022|\n",
      "|      18048|    officia s. dolor|1663482072|  1002143920|subscriber_100214...| 105|    105| plan_105|      0.030|           0.014|          0.007|             0.014|               0.020|\n",
      "|      14308|       culpa ullamco|2612856299|  1002265898|subscriber_100226...| 113|    113| plan_113|      0.015|           0.011|          0.006|             0.011|               0.020|\n",
      "|      43199|  consequat m. minim|8069130401|  1002320931|subscriber_100232...| 106|    106| plan_106|      0.020|           0.020|          0.006|             0.014|               0.017|\n",
      "|      47547|consequat m. eiusmod|9862074638|  1002407084|subscriber_100240...| 104|    104| plan_104|      0.010|           0.011|          0.001|             0.003|               0.002|\n",
      "|      17957|       magna i. quis|8922755506|  1002726877|subscriber_100272...| 110|    110| plan_110|      0.050|           0.020|          0.010|             0.018|               0.027|\n",
      "|      14374|    excepteur o. non|9410494311|  1002748152|subscriber_100274...| 112|    112| plan_112|      0.040|           0.018|          0.009|             0.020|               0.022|\n",
      "|       8317|          et nostrud|8150252879|  1002785514|subscriber_100278...| 108|    108| plan_108|      0.010|           0.001|          0.001|             0.003|               0.003|\n",
      "|      47319|       velit commodo|7923609333|  1003070151|subscriber_100307...| 117|    117| plan_117|      0.015|           0.008|          0.009|             0.019|               0.024|\n",
      "|      31689|    laborum q. culpa|1946167574|  1003183922|subscriber_100318...| 112|    112| plan_112|      0.040|           0.018|          0.009|             0.020|               0.022|\n",
      "+-----------+--------------------+----------+------------+--------------------+----+-------+---------+-----------+----------------+---------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customer_pricing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a756161-1c9c-4834-ba84-3c7ba0ff0cfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[device_id: decimal(10,0), total_mb: decimal(27,3), total_messages: bigint, total_ld_minutes: decimal(28,3), total_local_minutes: decimal(28,3), total_intl_minutes: decimal(28,3), event_count: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# lets compute the summary minutes messages and bytes transferred\n",
    "df_enriched_events = (df_events\n",
    "                      .withColumn(\"message_count\", F.expr(\"case when event_type='sms' then 1 else 0 end\"))\n",
    "                      .withColumn(\"ld_minutes\", F.expr(\"case when event_type='ld call' then cast(ceil(minutes) as decimal(18,3)) else 0.0 end\"))\n",
    "                      .withColumn(\"local_minutes\", F.expr(\"case when event_type='local call' then cast(ceil(minutes) as decimal(18,3)) else 0.0 end\"))\n",
    "                      .withColumn(\"intl_minutes\", F.expr(\"case when event_type='intl call' then cast(ceil(minutes) as decimal(18,3)) else 0.0 end\"))\n",
    "                     )\n",
    "\n",
    "df_enriched_events.createOrReplaceTempView(\"telephony_events\")\n",
    "\n",
    "df_summary = spark.sql(\"\"\"select device_id, \n",
    "                                 round(sum(bytes_transferred) / 1000000.0, 3) as total_mb, \n",
    "                                 sum(message_count) as total_messages,\n",
    "                                 sum(ld_minutes) as total_ld_minutes,\n",
    "                                 sum(local_minutes) as total_local_minutes,\n",
    "                                 sum(intl_minutes) as total_intl_minutes, \n",
    "                                 count(device_id) as event_count\n",
    "                                 from telephony_events\n",
    "                                 group by device_id\n",
    "                          \n",
    "\"\"\")\n",
    "\n",
    "df_summary.createOrReplaceTempView(\"event_summary\")\n",
    "\n",
    "display(df_summary.where(\"event_count > 0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------+----------------+-------------------+------------------+-----------+\n",
      "| device_id|total_mb|total_messages|total_ld_minutes|total_local_minutes|total_intl_minutes|event_count|\n",
      "+----------+--------+--------------+----------------+-------------------+------------------+-----------+\n",
      "|1954922029|4869.900|           629|        1473.000|           2345.000|           722.000|       1656|\n",
      "|9852527388|4634.819|           568|        1194.000|           2528.000|           727.000|       1561|\n",
      "|8578285899|4433.690|           591|        1403.000|           2257.000|           510.000|       1541|\n",
      "|9257138445|4692.269|           529|        1329.000|           2914.000|           672.000|       1533|\n",
      "|2749260882|4317.791|           560|        1463.000|           2513.000|           591.000|       1546|\n",
      "|9128361440|4162.059|           538|        1360.000|           2690.000|           623.000|       1478|\n",
      "|9087208703|4187.461|           569|        1342.000|           2274.000|           592.000|       1493|\n",
      "|1407627779|4505.466|           523|        1028.000|           2285.000|           799.000|       1515|\n",
      "|2744036337|4361.556|           606|        1228.000|           2729.000|           625.000|       1551|\n",
      "|1975565521|4232.122|           542|        1535.000|           2414.000|           719.000|       1491|\n",
      "|2467490796|4560.798|           550|        1187.000|           2365.000|           805.000|       1539|\n",
      "|9182549989|4703.922|           581|        1034.000|           2662.000|           703.000|       1556|\n",
      "|2547928192|4524.455|           525|        1276.000|           2439.000|           549.000|       1497|\n",
      "|1421070782|4210.611|           581|        1518.000|           2714.000|           629.000|       1535|\n",
      "|8622039960|4450.623|           608|        1442.000|           2886.000|           531.000|       1578|\n",
      "|8834017707|4592.501|           547|        1154.000|           2794.000|           848.000|       1541|\n",
      "|1408026076|3862.589|           599|        1517.000|           2111.000|           726.000|       1509|\n",
      "|3111049503|4186.467|           567|        1181.000|           2705.000|           755.000|       1512|\n",
      "|1277300638|4152.494|           555|        1149.000|           2524.000|           565.000|       1461|\n",
      "|2150020942|4033.915|           591|        1311.000|           2926.000|           617.000|       1573|\n",
      "+----------+--------+--------------+----------------+-------------------+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9628d6e-e347-4e8d-98f2-6f83ecd751a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[customer_id: decimal(10,0), customer_name: string, phone_number: decimal(10,0), email: string, plan_name: string, internet_cost: decimal(18,3), ld_cost: decimal(18,2), local_cost: decimal(18,2), intl_cost: decimal(18,2), sms_cost: decimal(18,2), total_invoice: decimal(23,3)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_customer_summary = (df_customer_pricing.join(df_summary,df_customer_pricing.device_id == df_summary.device_id )\n",
    "                       .createOrReplaceTempView(\"customer_summary\"))\n",
    "\n",
    "df_invoices = spark.sql(\"\"\"select *, \n",
    "                           internet_cost + sms_cost + ld_cost + local_cost + intl_cost as total_invoice \n",
    "                           from \n",
    "                             (select customer_id, customer_name, phone_number, email, plan_name, \n",
    "                             cast(round(total_mb * cost_per_mb, 2) as decimal(18,3)) as internet_cost,\n",
    "                             cast(round(total_ld_minutes * ld_cost_per_minute, 2) as decimal(18,2)) as ld_cost,\n",
    "                             cast(round(total_local_minutes * cost_per_minute, 2) as decimal(18,2)) as local_cost,\n",
    "                             cast(round(total_intl_minutes * intl_cost_per_minute, 2) as decimal(18,2)) as intl_cost,\n",
    "                             cast(round(total_messages * cost_per_message, 2) as decimal(18,2)) as sms_cost\n",
    "                             from customer_summary)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "display(df_invoices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+--------------------+---------+-------------+-------+----------+---------+--------+-------------+\n",
      "|customer_id|       customer_name|phone_number|               email|plan_name|internet_cost|ld_cost|local_cost|intl_cost|sms_cost|total_invoice|\n",
      "+-----------+--------------------+------------+--------------------+---------+-------------+-------+----------+---------+--------+-------------+\n",
      "|      12631| cupidatat h. cillum|  9908074451|subscriber_990807...| plan_108|       48.700|   4.42|      2.35|     2.17|    0.63|       58.270|\n",
      "|       3688|         qui laborum|  1577114986|subscriber_157711...| plan_101|      208.570|  15.52|     12.64|    10.91|   10.22|      257.860|\n",
      "|      41111|        ut w. mollit|  1290291097|subscriber_129029...| plan_110|      221.680|  25.25|     22.57|    13.77|   11.82|      295.090|\n",
      "|      16959|        excepteur ex|  2931211720|subscriber_293121...| plan_101|      211.150|  17.28|     14.57|    10.08|    9.52|      262.600|\n",
      "|      37009|    est exercitation|  8304955688|subscriber_830495...| plan_117|       64.770|  27.80|     22.62|    14.18|    4.48|      133.850|\n",
      "|      24659|adipiscing p. dolore|  8126429265|subscriber_812642...| plan_114|      166.480|  10.88|      8.07|     5.61|    8.61|      199.650|\n",
      "|      48674|          ex z. anim|  1274613760|subscriber_127461...| plan_118|       41.870|  29.52|     22.74|    22.50|    8.54|      125.170|\n",
      "|      22107|      officia labore|  3043871498|subscriber_304387...| plan_110|      225.270|  18.50|     22.85|    21.57|   10.46|      298.650|\n",
      "|      11635|           ut m. qui|  9284481815|subscriber_928448...| plan_117|       65.420|  23.33|     24.56|    15.00|    4.85|      133.160|\n",
      "|      11599|            in p. in|  8582399739|subscriber_858239...| plan_106|       84.640|  21.49|     14.48|    12.22|   10.84|      143.670|\n",
      "|      12460|          dolore non|  1250403722|subscriber_125040...| plan_110|      228.040|  21.37|     23.65|    21.74|   11.00|      305.800|\n",
      "|       4878|eiusmod r. voluptate|  1416525439|subscriber_141652...| plan_104|       47.040|   3.10|      2.66|     1.41|    6.39|       60.600|\n",
      "|      33030|      dolor proident|  3068214315|subscriber_306821...| plan_105|      135.730|  17.86|     17.07|    10.98|    7.35|      188.990|\n",
      "|      30945|          sed u. non|  8702998950|subscriber_870299...| plan_115|      126.320|  19.73|     19.00|    13.21|    5.81|      184.070|\n",
      "|      15040|    aute consectetur|  8125241670|subscriber_812524...| plan_109|      133.520|  27.40|     25.97|    11.15|    3.04|      201.080|\n",
      "|      27419|          eiusmod in|  8256436983|subscriber_825643...| plan_107|      114.810|  11.54|     16.76|    16.96|    9.30|      169.370|\n",
      "|      38400|      aliquip labore|  9301988611|subscriber_930198...| plan_116|       57.940|  28.82|     14.78|    13.07|    6.59|      121.200|\n",
      "|      32740|            quis sed|  8062756643|subscriber_806275...| plan_110|      209.320|  21.26|     27.05|    20.39|   11.34|      289.360|\n",
      "|      40695|     id i. cupidatat|  3068659475|subscriber_306865...| plan_118|       41.520|  25.28|     25.24|    21.47|    8.33|      121.840|\n",
      "|      10872|        commodo nisi|  1607388898|subscriber_160738...| plan_101|      181.530|  17.04|     14.63|     9.26|   10.64|      233.100|\n",
      "+-----------+--------------------+------------+--------------------+---------+-------------+-------+----------+---------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_invoices.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2d9baa3-3445-46e1-89a8-16edc44584e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(df_invoices.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4821a477-8ed6-49b4-9c6d-7010b4fe2a63",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Spider schema\n",
    "Using huggingface datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datasets import load_dataset_builder\n",
    "from datasets import load_dataset\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>Schema (values (type))</th>\n",
       "      <th>Primary Keys</th>\n",
       "      <th>Foreign Keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perpetrator</td>\n",
       "      <td>perpetrator : Perpetrator_ID (number) , People...</td>\n",
       "      <td>perpetrator : Perpetrator_ID | people : People_ID</td>\n",
       "      <td>perpetrator : People_ID equals people : People_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>college_2</td>\n",
       "      <td>classroom : building (text) , room_number (tex...</td>\n",
       "      <td>classroom : building | department : dept_name ...</td>\n",
       "      <td>course : dept_name equals department : dept_na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight_company</td>\n",
       "      <td>airport : id (number) , City (text) , Country ...</td>\n",
       "      <td>airport : id | operate_company : id | flight : id</td>\n",
       "      <td>flight : company_id equals operate_company : i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>icfp_1</td>\n",
       "      <td>Inst : instID (number) , name (text) , country...</td>\n",
       "      <td>Inst : instID | Authors : authID | Papers : pa...</td>\n",
       "      <td>Authorship : paperID equals Papers : paperID |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>body_builder</td>\n",
       "      <td>body_builder : Body_Builder_ID (number) , Peop...</td>\n",
       "      <td>body_builder : Body_Builder_ID | people : Peop...</td>\n",
       "      <td>body_builder : People_ID equals people : Peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>company_1</td>\n",
       "      <td>works_on : Essn (number) , Pno (number) , Hour...</td>\n",
       "      <td>works_on : Essn | employee : Ssn | department ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>workshop_paper</td>\n",
       "      <td>workshop : Workshop_ID (number) , Date (text) ...</td>\n",
       "      <td>workshop : Workshop_ID | submission : Submissi...</td>\n",
       "      <td>Acceptance : Workshop_ID equals workshop : Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>epinions_1</td>\n",
       "      <td>item : i_id (number) , title (text) | review :...</td>\n",
       "      <td>item : i_id | review : a_id | useracct : u_id</td>\n",
       "      <td>review : i_id equals item : i_id | review : u_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>party_host</td>\n",
       "      <td>party : Party_ID (number) , Party_Theme (text)...</td>\n",
       "      <td>party : Party_ID | host : Host_ID | party_host...</td>\n",
       "      <td>party_host : Party_ID equals party : Party_ID ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>product_catalog</td>\n",
       "      <td>Attribute_Definitions : attribute_id (number) ...</td>\n",
       "      <td>Attribute_Definitions : attribute_id | Catalog...</td>\n",
       "      <td>Catalog_Structure : catalog_id equals Catalogs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               db_id                             Schema (values (type))                                       Primary Keys                                       Foreign Keys\n",
       "0        perpetrator  perpetrator : Perpetrator_ID (number) , People...  perpetrator : Perpetrator_ID | people : People_ID  perpetrator : People_ID equals people : People_ID\n",
       "1          college_2  classroom : building (text) , room_number (tex...  classroom : building | department : dept_name ...  course : dept_name equals department : dept_na...\n",
       "2     flight_company  airport : id (number) , City (text) , Country ...  airport : id | operate_company : id | flight : id  flight : company_id equals operate_company : i...\n",
       "3             icfp_1  Inst : instID (number) , name (text) , country...  Inst : instID | Authors : authID | Papers : pa...  Authorship : paperID equals Papers : paperID |...\n",
       "4       body_builder  body_builder : Body_Builder_ID (number) , Peop...  body_builder : Body_Builder_ID | people : Peop...  body_builder : People_ID equals people : Peopl...\n",
       "..               ...                                                ...                                                ...                                                ...\n",
       "161        company_1  works_on : Essn (number) , Pno (number) , Hour...  works_on : Essn | employee : Ssn | department ...                                                   \n",
       "162   workshop_paper  workshop : Workshop_ID (number) , Date (text) ...  workshop : Workshop_ID | submission : Submissi...  Acceptance : Workshop_ID equals workshop : Wor...\n",
       "163       epinions_1  item : i_id (number) , title (text) | review :...      item : i_id | review : a_id | useracct : u_id  review : i_id equals item : i_id | review : u_...\n",
       "164       party_host  party : Party_ID (number) , Party_Theme (text)...  party : Party_ID | host : Host_ID | party_host...  party_host : Party_ID equals party : Party_ID ...\n",
       "165  product_catalog  Attribute_Definitions : attribute_id (number) ...  Attribute_Definitions : attribute_id | Catalog...  Catalog_Structure : catalog_id equals Catalogs...\n",
       "\n",
       "[166 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"richardr1126/spider-schema\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "df_schema = pd.DataFrame(dataset)\n",
    "df_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'business : bid (number) , business_id (text) , name (text) , full_address (text) , city (text) , latitude (text) , longitude (text) , review_count (number) , is_open (number) , rating (number) , state (text) | category : id (number) , business_id (text) , category_name (text) | user : uid (number) , user_id (text) , name (text) | checkin : cid (number) , business_id (text) , count (number) , day (text) | neighbourhood : id (number) , business_id (text) , neighbourhood_name (text) | review : rid (number) , business_id (text) , user_id (text) , rating (number) , text (text) , year (number) , month (text) | tip : tip_id (number) , business_id (text) , text (text) , user_id (text) , likes (number) , year (number) , month (text)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = list(df_schema.loc[df_schema['db_id'] == 'yelp']['Schema (values (type))'])[0]\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_field(s):\n",
    "    spark_types = {\n",
    "        'number': IntegerType(),\n",
    "        'text': StringType(),\n",
    "    }\n",
    "    match = re.match(r\"(.*?) \\((.*?)\\)\", s)\n",
    "    if match:\n",
    "        name, dtype = match.groups()\n",
    "        return StructField(name, spark_types[dtype])\n",
    "    else:\n",
    "        raise ValueError(f\"Unable to parse: {s}\")\n",
    "        \n",
    "def parse_table(s):\n",
    "    name, fields = s.split(\" : \")\n",
    "    struct_fields = [parse_field(f) for f in fields.split(\" , \")]\n",
    "    schema = StructType(struct_fields)\n",
    "    return name, schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': StructType([StructField('bid', IntegerType(), True), StructField('business_id', StringType(), True), StructField('name', StringType(), True), StructField('full_address', StringType(), True), StructField('city', StringType(), True), StructField('latitude', StringType(), True), StructField('longitude', StringType(), True), StructField('review_count', IntegerType(), True), StructField('is_open', IntegerType(), True), StructField('rating', IntegerType(), True), StructField('state', StringType(), True)]),\n",
       " 'category': StructType([StructField('id', IntegerType(), True), StructField('business_id', StringType(), True), StructField('category_name', StringType(), True)]),\n",
       " 'user': StructType([StructField('uid', IntegerType(), True), StructField('user_id', StringType(), True), StructField('name', StringType(), True)]),\n",
       " 'checkin': StructType([StructField('cid', IntegerType(), True), StructField('business_id', StringType(), True), StructField('count', IntegerType(), True), StructField('day', StringType(), True)]),\n",
       " 'neighbourhood': StructType([StructField('id', IntegerType(), True), StructField('business_id', StringType(), True), StructField('neighbourhood_name', StringType(), True)]),\n",
       " 'review': StructType([StructField('rid', IntegerType(), True), StructField('business_id', StringType(), True), StructField('user_id', StringType(), True), StructField('rating', IntegerType(), True), StructField('text', StringType(), True), StructField('year', IntegerType(), True), StructField('month', StringType(), True)]),\n",
       " 'tip': StructType([StructField('tip_id', IntegerType(), True), StructField('business_id', StringType(), True), StructField('text', StringType(), True), StructField('user_id', StringType(), True), StructField('likes', IntegerType(), True), StructField('year', IntegerType(), True), StructField('month', StringType(), True)])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_schemas = dict(parse_table(t) for t in schema.split(\" | \"))\n",
    "spark_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee93f8ca-fd40-4786-a1ad-587f5c525826",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dbldatagen as dg\n",
    "import dbldatagen.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee93f8ca-fd40-4786-a1ad-587f5c525826",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clear cache so that if we run multiple times to check performance, we're not relying on cache\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "shuffle_partitions_requested = 8\n",
    "partitions_requested = 1\n",
    "data_rows = 100\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", shuffle_partitions_requested)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('bid', IntegerType(), True), StructField('business_id', StringType(), True), StructField('name', StringType(), True), StructField('full_address', StringType(), True), StructField('city', StringType(), True), StructField('latitude', StringType(), True), StructField('longitude', StringType(), True), StructField('review_count', IntegerType(), True), StructField('is_open', IntegerType(), True), StructField('rating', IntegerType(), True), StructField('state', StringType(), True)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = spark_schemas['business']\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataspec = dg.DataGenerator(spark, rows=100, partitions=2).withSchema(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----+------------+----+--------+---------+------------+-------+------+-----+\n",
      "|bid|business_id|name|full_address|city|latitude|longitude|review_count|is_open|rating|state|\n",
      "+---+-----------+----+------------+----+--------+---------+------------+-------+------+-----+\n",
      "|  0|          0|   0|           0|   0|       0|        0|           0|      0|     0|    0|\n",
      "|  1|          1|   1|           1|   1|       1|        1|           1|      1|     1|    1|\n",
      "|  2|          2|   2|           2|   2|       2|        2|           2|      2|     2|    2|\n",
      "|  3|          3|   3|           3|   3|       3|        3|           3|      3|     3|    3|\n",
      "|  4|          4|   4|           4|   4|       4|        4|           4|      4|     4|    4|\n",
      "|  5|          5|   5|           5|   5|       5|        5|           5|      5|     5|    5|\n",
      "|  6|          6|   6|           6|   6|       6|        6|           6|      6|     6|    6|\n",
      "|  7|          7|   7|           7|   7|       7|        7|           7|      7|     7|    7|\n",
      "|  8|          8|   8|           8|   8|       8|        8|           8|      8|     8|    8|\n",
      "|  9|          9|   9|           9|   9|       9|        9|           9|      9|     9|    9|\n",
      "| 10|         10|  10|          10|  10|      10|       10|          10|     10|    10|   10|\n",
      "| 11|         11|  11|          11|  11|      11|       11|          11|     11|    11|   11|\n",
      "| 12|         12|  12|          12|  12|      12|       12|          12|     12|    12|   12|\n",
      "| 13|         13|  13|          13|  13|      13|       13|          13|     13|    13|   13|\n",
      "| 14|         14|  14|          14|  14|      14|       14|          14|     14|    14|   14|\n",
      "| 15|         15|  15|          15|  15|      15|       15|          15|     15|    15|   15|\n",
      "| 16|         16|  16|          16|  16|      16|       16|          16|     16|    16|   16|\n",
      "| 17|         17|  17|          17|  17|      17|       17|          17|     17|    17|   17|\n",
      "| 18|         18|  18|          18|  18|      18|       18|          18|     18|    18|   18|\n",
      "| 19|         19|  19|          19|  19|      19|       19|          19|     19|    19|   19|\n",
      "+---+-----------+----+------------+----+--------+---------+------------+-------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = dataspec.build()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataspec2 = (\n",
    "    dg.DataGenerator(spark, rows=100, partitions=2).withSchema(schema)\n",
    "    .withColumnSpec(\"business_id\", minValue=100, maxValue=10000, random=True)\n",
    "    .withColumnSpec(\"name\", text=dg.ILText(words=(2,3)))\n",
    "    .withColumnSpec(\"full_address\", template=r'\\n \\w \\w')\n",
    "    .withColumnSpec(\"city\", text=dg.ILText(words=(1,3)))\n",
    "    .withColumnSpec(\"latitude\", template=r'\\n.\\n\\n')\n",
    "    .withColumnSpec(\"longitude\", template=r'\\n.\\n\\n')\n",
    "    .withColumnSpec(\"review_count\", minValue=1, maxValue=1000, random=True, distribution=dist.Gamma(1.0, 2.0))\n",
    "    .withColumnSpec(\"is_open\", minValue=0, maxValue=1, random=True)\n",
    "    .withColumnSpec(\"rating\", minValue=1, maxValue=5, random=True)\n",
    "    .withColumnSpec(\"state\", values=[\"CA\", \"OR\", \"WA\", \"NV\", \"AZ\"], random=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------------------+--------------------+--------------------+----------+----------+------------+-------+------+-----+\n",
      "|bid|business_id|                name|        full_address|                city|  latitude| longitude|review_count|is_open|rating|state|\n",
      "+---+-----------+--------------------+--------------------+--------------------+----------+----------+------------+-------+------+-----+\n",
      "|  0|       5420|        Ut elit sed.|49 cupidatat repr...|         Mollit sed.| 126.10287| 53.124234|         133|      1|     4|   WA|\n",
      "|  1|       4168|Adipiscing cillum...|   237 dolor aliquip|         Laboris ut.| 16.171174|138.141184|         144|      0|     3|   NV|\n",
      "|  2|       6217|    Commodo commodo.|      109 anim velit|   Id proident duis.| 138.13053|118.155148|         142|      1|     2|   AZ|\n",
      "|  3|       6565|Aliquip dolor nos...|        127 velit in|              Magna.| 151.11278|   15.2094|          81|      1|     2|   CA|\n",
      "|  4|       9003|      Dolor ullamco.|     217 eiusmod sit|        Culpa ut eu.|245.125161|238.113157|         124|      1|     1|   CA|\n",
      "|  5|       3734| Aute aliqua dolore.|         250 enim in|              Nulla.|203.120210|   28.7554|          43|      1|     5|   NV|\n",
      "|  6|        524|Dolor aliquip dol...|     65 consequat id|Voluptate consect...| 249.20155|103.206158|         589|      0|     1|   AZ|\n",
      "|  7|       4228|      Deserunt duis.|95 adipiscing par...|      Minim commodo.| 54.208194| 14.216223|         226|      0|     2|   WA|\n",
      "|  8|       8922|      Mollit ea sit.|        10 sit culpa|           Deserunt.|  68.13029|177.174234|          87|      1|     4|   CA|\n",
      "|  9|       4619|            Elit ad.|     50 laborum sint|                Sit.|181.152206|189.208255|         423|      1|     3|   NV|\n",
      "| 10|       2085|In fugiat excepteur.|       24 in nostrud|            Non qui.|249.202218|  69.21128|         338|      1|     4|   NV|\n",
      "| 11|       7833|    Exercitation ea.|      136 magna anim|         Duis velit.| 15.162126|  106.1498|          29|      1|     5|   AZ|\n",
      "| 12|       8100|          Ea fugiat.|    21 proident anim|    Cupidatat dolor.| 53.251244|  65.52224|          27|      1|     4|   NV|\n",
      "| 13|       1867|      Do ullamco et.|   244 veniam mollit|Ullamco eiusmod qui.|   61.2192|  25.15983|         150|      0|     1|   CA|\n",
      "| 14|       1301|Dolore ipsum tempor.|  184 cupidatat sint|            Officia.|  11.14740|241.120242|         257|      1|     3|   WA|\n",
      "| 15|       4248|    Dolore occaecat.|    249 sunt aliquip|      Ullamco minim.|207.219116| 125.78183|         202|      0|     3|   NV|\n",
      "| 16|       2232|         Est tempor.|           233 ea in|            Esse in.| 10.104219|115.171221|         254|      0|     4|   AZ|\n",
      "| 17|       9389|         Duis minim.|      58 ut occaecat|             Fugiat.|   255.665| 65.217108|         389|      1|     3|   NV|\n",
      "| 18|       8264|Dolor reprehenderit.|        1 qui dolore|In exercitation r...| 161.23246|  204.9395|         190|      1|     2|   WA|\n",
      "| 19|       4672|Aliquip proident ...|      143 officia in|             Cillum.| 157.20515|  133.1754|          44|      0|     1|   OR|\n",
      "+---+-----------+--------------------+--------------------+--------------------+----------+----------+------------+-------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = dataspec2.build()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing sqlite DB\n",
    "Per: https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/from_to_dbms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leey/devpub/spark/python/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "import sqlite3\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "database = '/home/leey/devpub/spider/spider/database/college_1/college_1.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/12 01:14:40 WARN Dispatcher: Message RequestMessage(dgx2h0194.spark.sjc4.nvmetal.net:7077, NettyRpcEndpointRef(spark://AppClient@10.150.30.2:46353), ExecutorAdded(0,worker-20240412011406-10.150.30.2-45313,10.150.30.2:45313,6,16384)) dropped due to sparkEnv is stopped. Could not find AppClient.\n",
      "24/04/12 01:14:40 WARN Dispatcher: Message RequestMessage(dgx2h0194.spark.sjc4.nvmetal.net:7077, NettyRpcEndpointRef(spark://AppClient@10.150.30.2:46353), ExecutorAdded(1,worker-20240412011406-10.150.30.2-45313,10.150.30.2:45313,6,16384)) dropped due to sparkEnv is stopped. Could not find AppClient.\n"
     ]
    }
   ],
   "source": [
    "con = sqlite3.connect(database)\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### sample query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = cur.execute(\"\"\"\n",
    "SELECT T1.stu_fname \n",
    "FROM student AS T1 \n",
    "JOIN enroll AS T2 ON T1.stu_num  =  T2.stu_num \n",
    "JOIN CLASS AS T3 ON T2.class_code  =  T3.class_code \n",
    "JOIN course AS T4 ON T3.crs_code  =  T4.crs_code \n",
    "JOIN department AS T5 ON T5.dept_code  =  T4.dept_code \n",
    "WHERE T5.dept_name  =  'Accounting' \n",
    "INTERSECT \n",
    "SELECT T1.stu_fname FROM student AS T1 \n",
    "JOIN enroll AS T2 ON T1.stu_num  =  T2.stu_num \n",
    "JOIN CLASS AS T3 ON T2.class_code  =  T3.class_code \n",
    "JOIN course AS T4 ON T3.crs_code  =  T4.crs_code \n",
    "JOIN department AS T5 ON T5.dept_code  =  T4.dept_code \n",
    "WHERE T5.dept_name  =  'Computer Info. Systems'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anne',), ('William',)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read table into pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf = ps.read_sql(\"class\", con=\"jdbc:sqlite:/home/leey/devpub/spider/spider/database/college_1/college_1.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/11 21:01:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS_CODE</th>\n",
       "      <th>CRS_CODE</th>\n",
       "      <th>CLASS_SECTION</th>\n",
       "      <th>CLASS_TIME</th>\n",
       "      <th>CLASS_ROOM</th>\n",
       "      <th>PROF_NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10012</td>\n",
       "      <td>ACCT-211</td>\n",
       "      <td>1</td>\n",
       "      <td>MWF 8:00-8:50 a.m.</td>\n",
       "      <td>BUS311</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10013</td>\n",
       "      <td>ACCT-211</td>\n",
       "      <td>2</td>\n",
       "      <td>MWF 9:00-9:50 a.m.</td>\n",
       "      <td>BUS200</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10014</td>\n",
       "      <td>ACCT-211</td>\n",
       "      <td>3</td>\n",
       "      <td>TTh 2:30-3:45 p.m.</td>\n",
       "      <td>BUS252</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015</td>\n",
       "      <td>ACCT-212</td>\n",
       "      <td>1</td>\n",
       "      <td>MWF 10:00-10:50 a.m.</td>\n",
       "      <td>BUS311</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10016</td>\n",
       "      <td>ACCT-212</td>\n",
       "      <td>2</td>\n",
       "      <td>Th 6:00-8:40 p.m.</td>\n",
       "      <td>BUS252</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10017</td>\n",
       "      <td>CIS-220</td>\n",
       "      <td>1</td>\n",
       "      <td>MWF 9:00-9:50 a.m.</td>\n",
       "      <td>KLR209</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10018</td>\n",
       "      <td>CIS-220</td>\n",
       "      <td>2</td>\n",
       "      <td>MWF 9:00-9:50 a.m.</td>\n",
       "      <td>KLR211</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10019</td>\n",
       "      <td>CIS-220</td>\n",
       "      <td>3</td>\n",
       "      <td>MWF 10:00-10:50 a.m.</td>\n",
       "      <td>KLR209</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10020</td>\n",
       "      <td>CIS-420</td>\n",
       "      <td>1</td>\n",
       "      <td>W 6:00-8:40 p.m.</td>\n",
       "      <td>KLR209</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10021</td>\n",
       "      <td>QM-261</td>\n",
       "      <td>1</td>\n",
       "      <td>MWF 8:00-8:50 a.m.</td>\n",
       "      <td>KLR200</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10022</td>\n",
       "      <td>QM-261</td>\n",
       "      <td>2</td>\n",
       "      <td>TTh 1:00-2:15 p.m.</td>\n",
       "      <td>KLR200</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10023</td>\n",
       "      <td>QM-362</td>\n",
       "      <td>1</td>\n",
       "      <td>MWF 11:00-11:50 a.m.</td>\n",
       "      <td>KLR200</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10024</td>\n",
       "      <td>QM-362</td>\n",
       "      <td>2</td>\n",
       "      <td>TTh 2:30-3:45 p.m.</td>\n",
       "      <td>KLR200</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASS_CODE  CRS_CODE CLASS_SECTION            CLASS_TIME CLASS_ROOM  PROF_NUM\n",
       "0       10012  ACCT-211             1    MWF 8:00-8:50 a.m.     BUS311       105\n",
       "1       10013  ACCT-211             2    MWF 9:00-9:50 a.m.     BUS200       105\n",
       "2       10014  ACCT-211             3    TTh 2:30-3:45 p.m.     BUS252       342\n",
       "3       10015  ACCT-212             1  MWF 10:00-10:50 a.m.     BUS311       301\n",
       "4       10016  ACCT-212             2     Th 6:00-8:40 p.m.     BUS252       301\n",
       "5       10017   CIS-220             1    MWF 9:00-9:50 a.m.     KLR209       228\n",
       "6       10018   CIS-220             2    MWF 9:00-9:50 a.m.     KLR211       114\n",
       "7       10019   CIS-220             3  MWF 10:00-10:50 a.m.     KLR209       228\n",
       "8       10020   CIS-420             1      W 6:00-8:40 p.m.     KLR209       162\n",
       "9       10021    QM-261             1    MWF 8:00-8:50 a.m.     KLR200       114\n",
       "10      10022    QM-261             2    TTh 1:00-2:15 p.m.     KLR200       114\n",
       "11      10023    QM-362             1  MWF 11:00-11:50 a.m.     KLR200       162\n",
       "12      10024    QM-362             2    TTh 2:30-3:45 p.m.     KLR200       162"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = psdf.spark.frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------+--------------------+----------+--------+\n",
      "|CLASS_CODE|CRS_CODE|CLASS_SECTION|          CLASS_TIME|CLASS_ROOM|PROF_NUM|\n",
      "+----------+--------+-------------+--------------------+----------+--------+\n",
      "|     10012|ACCT-211|            1|  MWF 8:00-8:50 a.m.|    BUS311|     105|\n",
      "|     10013|ACCT-211|            2|  MWF 9:00-9:50 a.m.|    BUS200|     105|\n",
      "|     10014|ACCT-211|            3|  TTh 2:30-3:45 p.m.|    BUS252|     342|\n",
      "|     10015|ACCT-212|            1|MWF 10:00-10:50 a.m.|    BUS311|     301|\n",
      "|     10016|ACCT-212|            2|   Th 6:00-8:40 p.m.|    BUS252|     301|\n",
      "|     10017| CIS-220|            1|  MWF 9:00-9:50 a.m.|    KLR209|     228|\n",
      "|     10018| CIS-220|            2|  MWF 9:00-9:50 a.m.|    KLR211|     114|\n",
      "|     10019| CIS-220|            3|MWF 10:00-10:50 a.m.|    KLR209|     228|\n",
      "|     10020| CIS-420|            1|    W 6:00-8:40 p.m.|    KLR209|     162|\n",
      "|     10021|  QM-261|            1|  MWF 8:00-8:50 a.m.|    KLR200|     114|\n",
      "|     10022|  QM-261|            2|  TTh 1:00-2:15 p.m.|    KLR200|     114|\n",
      "|     10023|  QM-362|            1|MWF 11:00-11:50 a.m.|    KLR200|     162|\n",
      "|     10024|  QM-362|            2|  TTh 2:30-3:45 p.m.|    KLR200|     162|\n",
      "+----------+--------+-------------+--------------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('CLASS_CODE', StringType(), True), StructField('CRS_CODE', StringType(), True), StructField('CLASS_SECTION', StringType(), True), StructField('CLASS_TIME', StringType(), True), StructField('CLASS_ROOM', StringType(), True), StructField('PROF_NUM', LongType(), True)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbldatagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dbldatagen as dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/11 21:03:44 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Code snippet generated with Databricks Labs Data Generator (`dbldatagen`) DataAnalyzer class\n",
      "# Install with `pip install dbldatagen` or in notebook with `%pip install dbldatagen`\n",
      "# See the following resources for more details:\n",
      "#\n",
      "#   Getting Started - [https://databrickslabs.github.io/dbldatagen/public_docs/APIDOCS.html]\n",
      "#   Github project - [https://github.com/databrickslabs/dbldatagen]\n",
      "#\n",
      "import dbldatagen as dg\n",
      "import pyspark.sql.types\n",
      "\n",
      "# Column definitions are stubs only - modify to generate correct data  \n",
      "#\n",
      "generation_spec = (\n",
      "    dg.DataGenerator(sparkSession=spark, \n",
      "                     name='synthetic_data', \n",
      "                     rows=100000,\n",
      "                     random=True,\n",
      "                     )\n",
      "    .withColumn('CLASS_CODE', 'string', template=r'\\\\w')\n",
      "    .withColumn('CRS_CODE', 'string', template=r'\\\\w')\n",
      "    .withColumn('CLASS_SECTION', 'string', template=r'\\\\w')\n",
      "    .withColumn('CLASS_TIME', 'string', template=r'\\\\w')\n",
      "    .withColumn('CLASS_ROOM', 'string', template=r'\\\\w')\n",
      "    .withColumn('PROF_NUM', 'bigint', minValue=105, maxValue=342)\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "analyzer = dg.DataAnalyzer(sparkSession=spark, df=df)\n",
    "generatedCode = analyzer.scriptDataGeneratorFromData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dbldatagen as dg\n",
    "import pyspark.sql.types\n",
    "\n",
    "# Column definitions are stubs only - modify to generate correct data  \n",
    "#\n",
    "generation_spec = (\n",
    "    dg.DataGenerator(sparkSession=spark, \n",
    "                     name='synthetic_data', \n",
    "                     rows=100000,\n",
    "                     random=True,\n",
    "                     )\n",
    "    .withColumn('CLASS_CODE', 'string', template=r'\\\\w')\n",
    "    .withColumn('CRS_CODE', 'string', template=r'\\\\w')\n",
    "    .withColumn('CLASS_SECTION', 'string', template=r'\\\\w')\n",
    "    .withColumn('CLASS_TIME', 'string', template=r'\\\\w')\n",
    "    .withColumn('CLASS_ROOM', 'string', template=r'\\\\w')\n",
    "    .withColumn('PROF_NUM', 'bigint', minValue=105, maxValue=342)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+------------+------------+--------+\n",
      "|CLASS_CODE|     CRS_CODE|CLASS_SECTION|  CLASS_TIME|  CLASS_ROOM|PROF_NUM|\n",
      "+----------+-------------+-------------+------------+------------+--------+\n",
      "|        ad|       tempor|     pariatur|     eiusmod|     nostrud|     297|\n",
      "|       non|    cupidatat|  consectetur|     commodo|        enim|     227|\n",
      "|   laboris|           in|  consectetur|          ut|     commodo|     186|\n",
      "|      amet|      officia|   incididunt|       nulla|         est|     307|\n",
      "|   commodo|     proident|   incididunt|    occaecat|       ipsum|     327|\n",
      "|    labore|       dolore|         duis|      fugiat|      mollit|     296|\n",
      "|   eiusmod|           id|  consectetur|exercitation|          in|     302|\n",
      "|   officia|        dolor|    consequat|      tempor|        anim|     177|\n",
      "|     magna|       cillum|          sed|          ex|          ad|     137|\n",
      "|     culpa|        nulla|         elit|     laboris|        anim|     267|\n",
      "|   laborum|reprehenderit|     pariatur|        anim|          do|     296|\n",
      "|     lorem|   incididunt|       dolore|      dolore|   voluptate|     260|\n",
      "| cupidatat|    voluptate|    excepteur|          ea|   excepteur|     280|\n",
      "| consequat|      laborum|       aliqua|         sed|         qui|     200|\n",
      "|        ea|        dolor|        nulla| consectetur|        aute|     318|\n",
      "|        ex| exercitation|       dolore|       magna|exercitation|     245|\n",
      "|      nisi|         nisi|           ut|      dolore|       culpa|     266|\n",
      "|        ut|         nisi|        ipsum|       nulla|        sunt|     191|\n",
      "|   aliquip|      laborum|        dolor|     officia|       magna|     135|\n",
      "|      aute|   incididunt|    consequat|        sunt|   excepteur|     275|\n",
      "+----------+-------------+-------------+------------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_synthetic = generation_spec.build()\n",
    "df_synthetic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_synthetic.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_joined = df.union(df_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_joined.createOrReplaceTempView(\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = spark.sql(\"SELECT * from class where CRS_CODE='ACCT-211'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------+------------------+----------+--------+\n",
      "|CLASS_CODE|CRS_CODE|CLASS_SECTION|        CLASS_TIME|CLASS_ROOM|PROF_NUM|\n",
      "+----------+--------+-------------+------------------+----------+--------+\n",
      "|     10012|ACCT-211|            1|MWF 8:00-8:50 a.m.|    BUS311|     105|\n",
      "|     10013|ACCT-211|            2|MWF 9:00-9:50 a.m.|    BUS200|     105|\n",
      "|     10014|ACCT-211|            3|TTh 2:30-3:45 p.m.|    BUS252|     342|\n",
      "+----------+--------+-------------+------------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "datagen",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
